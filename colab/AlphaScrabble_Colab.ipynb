{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AlphaScrabble: AlphaZero-style Scrabble Engine\n",
        "\n",
        "This notebook demonstrates a complete AlphaZero-style Scrabble engine with:\n",
        "- Monte Carlo Tree Search (MCTS) with neural network guidance\n",
        "- GADDAG/DAWG lexicon for move generation\n",
        "- Self-play training pipeline\n",
        "- Interactive gameplay\n",
        "\n",
        "**Ready to run in Google Colab Pro with GPU support!**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup and Installation\n",
        "\n",
        "Install all required dependencies and setup the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install system dependencies\n",
        "!apt-get update\n",
        "!apt-get install -y qtbase5-dev libqt5core5a build-essential cmake ninja-build\n",
        "\n",
        "# Install Python dependencies\n",
        "!pip install -U pip wheel cmake ninja pybind11 pytest tensorboard pandas pyarrow rich tqdm click\n",
        "\n",
        "# Install PyTorch with CUDA support\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "print(\"‚úÖ Dependencies installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone and install AlphaScrabble\n",
        "!git clone https://github.com/alphascrabble/alphascrabble.git\n",
        "!cd alphascrabble && pip install -e .\n",
        "\n",
        "print(\"‚úÖ AlphaScrabble installed successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Lexicon Setup\n",
        "\n",
        "Download and compile the English Scrabble lexicon from ENABLE1 word list.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "from pathlib import Path\n",
        "\n",
        "# Create lexicon cache directory\n",
        "lexica_dir = Path(\"lexica_cache\")\n",
        "lexica_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Download ENABLE1 word list\n",
        "enable1_url = \"https://norvig.com/ngrams/enable1.txt\"\n",
        "enable1_path = lexica_dir / \"enable1.txt\"\n",
        "\n",
        "if not enable1_path.exists():\n",
        "    print(\"üì• Downloading ENABLE1 word list...\")\n",
        "    response = requests.get(enable1_url)\n",
        "    with open(enable1_path, 'w') as f:\n",
        "        f.write(response.text)\n",
        "    print(f\"‚úÖ Downloaded {enable1_path}\")\n",
        "else:\n",
        "    print(f\"‚úÖ ENABLE1 already exists: {enable1_path}\")\n",
        "\n",
        "# Show first few words\n",
        "with open(enable1_path, 'r') as f:\n",
        "    words = f.read().strip().split('\\n')[:10]\n",
        "    print(f\"üìù First 10 words: {', '.join(words)}\")\n",
        "    print(f\"üìä Total words: {len(f.read().strip().split('\\n'))}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Neural Network Demo\n",
        "\n",
        "Create and test the neural network architecture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import sys\n",
        "sys.path.append('alphascrabble')\n",
        "\n",
        "from alphascrabble.nn.model import AlphaScrabbleNet\n",
        "from alphascrabble.engine.features import FeatureExtractor\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üñ•Ô∏è  Using device: {device}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# Create neural network\n",
        "print(\"üß† Creating neural network...\")\n",
        "model = AlphaScrabbleNet().to(device)\n",
        "print(f\"‚úÖ Model created with {sum(p.numel() for p in model.parameters())} parameters\")\n",
        "\n",
        "# Test forward pass\n",
        "print(\"üß™ Testing forward pass...\")\n",
        "feature_extractor = FeatureExtractor()\n",
        "\n",
        "# Create dummy features\n",
        "board_features = np.random.rand(32, 15, 15).astype(np.float32)\n",
        "rack_features = np.random.rand(27).astype(np.float32)\n",
        "move_features = np.random.rand(5, 64).astype(np.float32)\n",
        "\n",
        "# Convert to tensors\n",
        "board_tensor = torch.FloatTensor(board_features).unsqueeze(0).to(device)\n",
        "rack_tensor = torch.FloatTensor(rack_features).unsqueeze(0).to(device)\n",
        "move_tensor = torch.FloatTensor(move_features).unsqueeze(0).to(device)\n",
        "\n",
        "# Forward pass\n",
        "with torch.no_grad():\n",
        "    policy_logits, value = model(board_tensor, rack_tensor, move_tensor)\n",
        "\n",
        "print(f\"‚úÖ Forward pass successful!\")\n",
        "print(f\"üìä Policy logits shape: {policy_logits.shape}\")\n",
        "print(f\"üìä Value shape: {value.shape}\")\n",
        "print(f\"üìä Value range: [{value.min().item():.3f}, {value.max().item():.3f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
